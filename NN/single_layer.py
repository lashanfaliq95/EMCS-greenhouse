# import the required libraries
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split


# define the one hot encode function
def one_hot_encode(labels):
    n_labels = len(labels)
    n_unique_labels = len(np.unique(labels))
    one_hot_encode = np.zeros((n_labels, n_unique_labels))
    one_hot_encode[np.arange(n_labels), labels] = 1
    return one_hot_encode


# Read the  dataset
df = pd.read_csv("Dataset/train_dataset.csv")
df = df.dropna()
print(len(df.columns))
X = df[df.columns[3:7]].values
y = df[df.columns[7]]
# encode the dependent variable containing categorical values
encoder = LabelEncoder()
encoder.fit(y)
y = encoder.transform(y)
Y = one_hot_encode(y)

# Transform the data in training and testing
X, Y = shuffle(X, Y, random_state=1)
train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=42)

# define and initialize the variables to work with the tensors
learning_rate = 0.1
training_epochs = 1000

# Array to store cost obtained in each epoch
cost_history = np.empty(shape=[1], dtype=float)

n_dim = X.shape[1]
n_class = 2

x = tf.placeholder(tf.float32, [None, n_dim])
W = tf.Variable(tf.zeros([n_dim, n_class]))
b = tf.Variable(tf.zeros([n_class]))

# initialize all variables.
init = tf.global_variables_initializer()

# define the cost function
y_ = tf.placeholder(tf.float32, [None, n_class])
y = tf.nn.softmax(tf.matmul(x, W) + b)
cost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)), reduction_indices=[1]))
training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)

# initialize the session
sess = tf.Session()
sess.run(init)
mse_history = []

# calculate the cost for each epoch
for epoch in range(training_epochs):
    sess.run(training_step, feed_dict={x: train_x, y_: train_y})
    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})
    cost_history = np.append(cost_history, cost)
    print('epoch : ', epoch, ' - ', 'cost: ', cost)

pred_y = sess.run(y, feed_dict={x: test_x})

# Calculate Accuracy
correct_prediction = tf.equal(tf.argmax(pred_y, 1), tf.argmax(test_y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print("Test Accuracy: ", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))

plt.plot(range(len(cost_history)), cost_history)
plt.axis([0, training_epochs, 0, np.max(cost_history)])
plt.show()